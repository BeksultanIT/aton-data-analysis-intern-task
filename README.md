# АТОН — Тестовое задание стажёра группы анализа данных

> Решение тестового задания для позиции **Стажёр группы анализа данных** в инвестиционной компании **АТОН** (февраль 2026).

---

## Содержание

- [Стек технологий](#стек-технологий)
- [Задание 1: Анализ финансовых транзакций](#задание-1-анализ-финансовых-транзакций)
- [Задание 2: Краулер документов с полнотекстовым поиском](#задание-2-краулер-документов-с-полнотекстовым-поиском)
- [Быстрый старт](#быстрый-старт)

---

## Стек технологий

| Библиотека / Инструмент | Применение |
|------------------------|------------|
| `pandas`, `numpy` | Обработка и анализ данных |
| `matplotlib`, `seaborn` | Визуализация |
| `scikit-learn` | Линейная регрессия (прогноз выручки) |
| `sqlite3` (встроен) | Хранение индекса, полнотекстовый поиск (FTS5) |
| `python-docx`, `pdfplumber`, `openpyxl` | Парсинг документов |
| `py7zr`, `zipfile` | Работа с архивами |

---

## Задание 1: Анализ финансовых транзакций

### Что сделано

**Очистка и предобработка данных:**
- Удалены строки с некорректными датами и пустыми суммами
- Отрицательные значения заменены модулем
- Пропуски в текстовых полях заполнены заглушкой

**Анализ транзакций:**
- Топ-5 услуг по количеству транзакций
- Средний чек по городам
- Самая доходная услуга
- Распределение по способам оплаты
- Выручка за последний месяц

**Работа с клиентами:**
- Left join с данными клиентов по `client_id`
- Категоризация клиентов по уровню капитала: `< 100k` / `100k – 1M` / `> 1M`

**Визуализация:** 3 графика, сохранены в `plots/`

**Прогноз:** выручка на следующий месяц (LinearRegression + MAE на трейне)

### Структура

```
aton_intern_task1/
├── aton_intern_task1.ipynb   
├── clients_data.json
├── transactions_data.xlsx
├── README.md
└── requirements.txt
```

### Запуск

```bash
# Установить зависимости
pip install -r requirements.txt

# Открыть ноутбук
jupyter notebook aton_intern_task1.ipynb
# или
jupyter lab
```

---

## Задание 2: Краулер документов с полнотекстовым поиском

### Что сделано

Скрипт `crawler/crawler.py` сканирует указанную директорию, извлекает текст из файлов форматов `.docx`, `.xlsx`, `.pdf`, `.txt`, а также из архивов `.zip` и `.7z`. Результат сохраняется в CSV и импортируется в SQLite с поддержкой полнотекстового поиска (FTS5).

### Структура

```
crawler/
├── crawler.py            
├── search.py             
├── generate_samples.py   
├── output/
│   └── index.csv
└── storage/
    ├── data_table.xlsx
    ├── presentation.pdf
    └── archive.zip
```

### Запуск

```bash
cd crawler

# 1. Сгенерировать тестовые файлы
python generate_samples.py

# 2. Запустить краулер
python crawler.py --root storage/ --output output/index.csv

# 3. Поиск по базе
python search.py --query "инвестиции" --db output/fti.db
```

### Зависимости

```bash
pip install python-docx openpyxl pdfplumber py7zr
```

---

## Быстрый старт

```bash
# Клонировать репозиторий
git clone https://github.com/твой_ник/aton-data-analysis-intern-task.git
cd aton-data-analysis-intern-task

# Установить зависимости
pip install -r requirements.txt
```

---

*Готов к обсуждению решения на собеседовании.*